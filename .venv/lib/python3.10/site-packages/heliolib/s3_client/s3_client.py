import logging
from io import StringIO

import pandas as pd
from botocore.exceptions import ClientError

logger = logging.getLogger(__name__)


class S3Client:
    """
    Class for extracting data from an S3 bucket.

    Parameters:
    -----------
    bucket_name: str
        The name of the S3 bucket.
    s3_client: boto3.client
        The S3 client.

    Examples:
    ---------
    >>> from heliolib.s3_client import S3Client
    >>> import boto3
    >>> bucket_name = "bucket_name"
    >>> boto_s3_client = boto3.client("s3")
    >>> object_s3_extractor = S3Client(bucket_name, boto_s3_client)
    >>> file_key = "path/to/file.csv"

    Raises:
    -------
    TypeError
        If the bucket_name is not a string.
    ValueError
        If the bucket does not exist.
    FileNotFoundError
        If the bucket does not exist in the bucket

    Methods:
    --------
    read_object(file_key)
        Get an S3 object using the bucket name and the file key.
    write_object(content, file_key)
        Write/Persist data to the bucket in S3.
    save_pandas_dataframe(dataframe, file_key)
        Ingests a dataframe into S3.
    """

    def __init__(self, bucket_name: str, boto_s3_client):
        """
        Initializes the S3DataExtractor class.

        Parameters:
        -----------
        bucket_name: str
            The name of the S3 bucket.
        boto_s3_client: boto3.client
            The S3 client.

        Raises:
        -------
        TypeError
            If the bucket_name is not a string.
        ValueError
            If the bucket does not exist.
        """
        if not isinstance(bucket_name, str):
            raise TypeError("bucket_name must be a string.")
        self.boto_s3_client = boto_s3_client
        self._validate_bucket_exists(bucket_name=bucket_name)
        self.bucket_name = bucket_name
        # Log the initialization of DataExtractor for the bucket
        logger.info(f"Initializing S3DataExtractor for bucket {bucket_name}")

    def _validate_bucket_exists(self, bucket_name: str):
        """
        Validates if a bucket exists in the S3 client.
        This method will be called in the constructor.
        It uses head_bucket() to check if the bucket exists.

        Raises:
        -------
        ValueError
            If the bucket does not exist.
        """
        try:
            self.boto_s3_client.head_bucket(Bucket=bucket_name)
            logger.debug(f"Bucket {bucket_name} exists in S3")
            return True
        except ClientError as e:
            error_code = int(e.response["Error"]["Code"])
            if error_code == 403:
                raise ValueError(f"Bucket {bucket_name} is private. Forbidden access.")
            elif error_code == 404:
                raise ValueError(f"Bucket {bucket_name} does not exist.")

    def read_object(self, file_key: str):
        """
        Get an S3 object using the bucket name and the file key.

        Parameters:
        -----------
        file_key: str
            The key of the file in the S3 bucket.

        Returns:
        --------
        obj: S3 object
            The S3 object associated with the bucket name and the file key.
        """
        try:
            response = self.boto_s3_client.get_object(
                Bucket=self.bucket_name, Key=file_key
            )
            logger.debug(
                f"Fetched an S3 object using the bucket {self.bucket_name} and the file key {file_key}."
            )
            return response["Body"].read()
        except ClientError as e:
            if e.response["Error"]["Code"] == "NoSuchKey":
                raise FileNotFoundError(
                    f"File {file_key} not found in the bucket {self.bucket_name}."
                )
            else:
                # Re-raise the exception if it's not a NoSuchKey error
                raise

    def write_object(self, content: StringIO, file_key: str):
        """
        Write/Persist data to the bucket in S3.

        Parameters
        ----------
        content : StringIO
            The content to be written
        file_key : str
            The filename/file path
        """
        self.boto_s3_client.put_object(
            Bucket=self.bucket_name,
            Body=content.getvalue(),
            Key=file_key,
        )
        logger.debug(f"File {file_key} written to bucket {self.bucket_name}.")

    def save_pandas_dataframe(self, dataframe: pd.DataFrame, file_key: str):
        """
        Ingests a dataframe into S3.

        Parameters:
        -----------
        dataframe: pandas.DataFrame
            The dataframe to ingest.
        file_key: str
            Filename/file path
        """
        csv_buffer = StringIO()
        dataframe.to_csv(csv_buffer)

        self.write_object(content=csv_buffer, file_key=file_key)
        logger.debug(
            f"Ingestion to bucket {self.bucket_name} with file {file_key} completed."
        )
