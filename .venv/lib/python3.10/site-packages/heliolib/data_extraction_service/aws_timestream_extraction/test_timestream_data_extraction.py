"""
Unit tests for the TimestreamDataExtractor class.
"""

import os
from datetime import datetime
from unittest.mock import MagicMock, patch

import pandas as pd
import pytest

from heliolib.data_extraction_service import TimestreamDataExtractor


class Dotdict(dict):
    """dot.notation access to dictionary attributes"""

    __getattr__ = dict.get
    __setattr__ = dict.__setitem__
    __delattr__ = dict.__delitem__


@pytest.fixture
def valid_timestream_extractor_object():
    """
    Returns a valid TimestreamDataExtractor object for testing.
    Returns:
        TimestreamDataExtractor: An instance of TimestreamDataExtractor.
    """
    valid_aws_timestream_client = MagicMock()
    valid_aws_session = MagicMock()
    extractor = TimestreamDataExtractor(
        aws_timestream_client=valid_aws_timestream_client,
        metadata_api_object=MagicMock(),
        boto3_session=valid_aws_session,
    )
    return extractor


def test_initialization_timestream_data_extractor_raises_with_invalid_aws_timestream_client():
    invalid_aws_timestream_client = Dotdict({})
    valid_metadata_api_object = MagicMock()
    aws_session = MagicMock()
    with pytest.raises(ValueError) as e:
        TimestreamDataExtractor(
            aws_timestream_client=invalid_aws_timestream_client,
            metadata_api_object=valid_metadata_api_object,
            boto3_session=aws_session,
        )
    assert str(e.value) == "aws_timestream_client cannot be None or lacks query method."


def test_initialize_aws_session_with_region_set():
    with patch.dict("os.environ", {"AWS_REGION": "us-west-1"}):
        with patch(
            "boto3.Session", MagicMock(return_value=MagicMock(region_name="us-west-1"))
        ) as mock_session:
            session = TimestreamDataExtractor._initialize_boto3_session()
            mock_session.assert_called_once_with(region_name="us-west-1")
            assert session.region_name == "us-west-1"


def test_initialize_aws_session_without_region_set():
    with patch.dict("os.environ", {}, clear=True):
        with pytest.raises(ValueError) as e:
            TimestreamDataExtractor._initialize_boto3_session()
        assert str(e.value) == "AWS_REGION not set in the environment variables"


def test_prepare_query_returns_correct_query():
    valid_aws_timestream_client = MagicMock()
    valid_plant_id = 123
    valid_metadata_api_object = MagicMock()
    valid_metadata_api_object.get_company_name.return_value = "TestCompany"
    valid_aws_session = MagicMock()
    start_datetime = pd.to_datetime("2021-01-01 00:00:00")
    end_datetime = pd.to_datetime("2021-01-02 23:59:59")
    extractor = TimestreamDataExtractor(
        aws_timestream_client=valid_aws_timestream_client,
        metadata_api_object=valid_metadata_api_object,
        boto3_session=valid_aws_session,
    )
    extractor.plant_id = valid_plant_id
    extractor.company_name = "TestCompany"
    query = extractor._prepare_query(start_datetime, end_datetime)
    assert (
        query
        == f"SELECT * FROM \"TestCompany\".Plant_{valid_plant_id} WHERE time between '2021-01-01 00:00:00' and '2021-01-02 23:59:59'"
    )


def test_fetch_data_for_date_success(valid_timestream_extractor_object):
    start_datetime = datetime(2021, 1, 1)
    end_datetime = datetime(2021, 1, 2)
    valid_plant_id = 123
    valid_metadata_api_object = MagicMock()
    valid_metadata_api_object.get_company_name.return_value = "TestCompany"
    mock_df = pd.DataFrame({"data": [1, 2, 3]})  # Mocked data

    with patch.object(
        valid_timestream_extractor_object, "_prepare_query"
    ) as mock_prepare_query, patch.object(
        valid_timestream_extractor_object, "_query_timestream_db", return_value=mock_df
    ) as mock_query_db:
        result = valid_timestream_extractor_object.fetch_data(
            plant_id=valid_plant_id,
            start_datetime=start_datetime,
            end_datetime=end_datetime,
        )

    mock_prepare_query.assert_called_once_with(start_datetime, end_datetime)
    assert mock_query_db.called
    assert result.equals(mock_df)


def test_fetch_data_for_date_exception(valid_timestream_extractor_object):
    start_datetime = datetime(2021, 1, 1)
    end_datetime = datetime(2021, 1, 2)
    valid_plant_id = 123
    valid_metadata_api_object = MagicMock()
    valid_metadata_api_object.get_company_name.return_value = "TestCompany"

    with patch.object(
        valid_timestream_extractor_object, "_prepare_query"
    ) as mock_prepare_query, patch.object(
        valid_timestream_extractor_object,
        "_query_timestream_db",
        side_effect=Exception("Test Exception"),
    ) as mock_query_db:
        result = valid_timestream_extractor_object.fetch_data(
            plant_id=valid_plant_id,
            start_datetime=start_datetime,
            end_datetime=end_datetime,
        )

    mock_prepare_query.assert_called_once_with(start_datetime, end_datetime)
    assert mock_query_db.called
    assert result.empty


def test_process_data_non_empty_with_measure_name():
    sample_data = pd.DataFrame(
        {
            "time": ["2021-01-01 00:00:00", "2021-01-01 01:00:00"],
            "measure_name": ["value1", "value2"],
            "value": [100, -999],
        }
    )
    expected_data = pd.DataFrame(
        {"value": [100, None]},
        index=pd.Index(["2021-01-01 00:00:00", "2021-01-01 01:00:00"], name="datetime"),
    )

    processed_data = TimestreamDataExtractor._preprocess_data(sample_data)
    pd.testing.assert_frame_equal(processed_data, expected_data)


def test_process_data_empty():
    empty_data = pd.DataFrame()
    processed_data = TimestreamDataExtractor._preprocess_data(empty_data)
    assert processed_data.empty


def test_process_data_none():
    processed_data = TimestreamDataExtractor._preprocess_data(None)
    assert processed_data.empty


def test_combine_chunks_multiple_non_empty(valid_timestream_extractor_object):
    chunk1 = pd.DataFrame(
        {
            "time": ["2021-01-01 00:00:00", "2021-01-01 01:00:00"],
            "measure_name": ["value1", "value2"],
            "data": [1, 2],
        }
    )
    chunk2 = pd.DataFrame(
        {
            "time": ["2021-01-01 02:00:00", "2021-01-01 03:00:00"],
            "measure_name": ["value3", "value4"],
            "data": [3, 4],
        }
    )
    non_empty_data_query_iterator = iter([chunk1, chunk2])
    combined_data = valid_timestream_extractor_object._combine_processed_chunks_of_data(
        query_iterator=non_empty_data_query_iterator
    )
    expected_data = pd.DataFrame(
        {
            "data": [1, 2, 3, 4],
            "datetime": [
                "2021-01-01 00:00:00",
                "2021-01-01 01:00:00",
                "2021-01-01 02:00:00",
                "2021-01-01 03:00:00",
            ],
        }
    )
    expected_data.set_index("datetime", inplace=True)
    pd.testing.assert_frame_equal(combined_data, expected_data)


def test_combine_chunks_mixed_empty_non_empty(valid_timestream_extractor_object):
    non_empty_chunk = pd.DataFrame(
        {"time": ["2021-01-01"], "measure_name": ["value1"], "data": [1]}
    )
    empty_chunk = pd.DataFrame(columns=["time", "measure_name", "data"])

    query_iterator = iter([non_empty_chunk, empty_chunk])

    combined_data = valid_timestream_extractor_object._combine_processed_chunks_of_data(
        query_iterator
    )
    expected_data = pd.DataFrame(
        {"data": [1]}, index=pd.Index(["2021-01-01"], name="datetime")
    )
    pd.testing.assert_frame_equal(combined_data, expected_data)


def test_combine_chunks_all_empty(valid_timestream_extractor_object):
    empty_chunk = pd.DataFrame()
    query_iterator = iter([empty_chunk, empty_chunk])

    combined_data = valid_timestream_extractor_object._combine_processed_chunks_of_data(
        query_iterator
    )
    assert combined_data.empty


def test_combine_chunks_empty_iterator(valid_timestream_extractor_object):
    query_iterator = iter([])
    combined_data = valid_timestream_extractor_object._combine_processed_chunks_of_data(
        query_iterator
    )
    assert combined_data.empty


def dataframe_generator_from_test_file():
    """
    Returns a generator that yields a DataFrame from a test CSV file.
    """
    test_file_path = os.path.join(os.path.dirname(__file__), "test_data_timestream.csv")
    test_data_frame = pd.read_csv(test_file_path)
    yield test_data_frame


def test_fetch_data_with_no_params_raises_value_error(
    valid_timestream_extractor_object,
):
    with pytest.raises(ValueError) as e:
        valid_timestream_extractor_object.fetch_data()
    assert (
        str(e.value)
        == "Must provide either a date range with plant id or a custom SQL query."
    )


def test_fetch_data_with_custom_sql_query_and_other_params_raises_error(
    valid_timestream_extractor_object,
):
    custom_sql_query = "SELECT * FROM my_table WHERE time between '2024-05-01 00:00:00' and '2024-05-02 23:59:00'"
    valid_plant_id = 123
    start_datetime = datetime(2024, 5, 1, hour=0, minute=0, second=0)
    end_datetime = datetime(2024, 5, 2, hour=23, minute=59, second=59)

    with pytest.raises(ValueError) as e:
        valid_timestream_extractor_object.fetch_data(
            plant_id=valid_plant_id,
            start_datetime=start_datetime,
            end_datetime=end_datetime,
            custom_sql_query=custom_sql_query,
        )
    assert (
        str(e.value)
        == "Must provide either a plant id with date range or a custom SQL query, not both."
    )


def test_fetch_data_with_missing_plant_id_raises_error(
    valid_timestream_extractor_object,
):
    start_datetime = datetime(2021, 1, 1)
    end_datetime = datetime(2021, 1, 2)

    with pytest.raises(ValueError) as e:
        valid_timestream_extractor_object.fetch_data(
            start_datetime=start_datetime,
            end_datetime=end_datetime,
        )
    assert (
        str(e.value)
        == "Must provide either a date range with plant id or a custom SQL query."
    )


def test_fetch_data_with_missing_date_range_raises_error(
    valid_timestream_extractor_object,
):
    valid_plant_id = 123

    with pytest.raises(ValueError) as e:
        valid_timestream_extractor_object.fetch_data(
            plant_id=valid_plant_id,
        )
    assert (
        str(e.value)
        == "Must provide either a date range with plant id or a custom SQL query."
    )


def test_fetch_data_with_invalid_plant_id_raises_error(
    valid_timestream_extractor_object,
):
    invalid_plant_id = "123"
    start_datetime = datetime(2021, 1, 1)
    end_datetime = datetime(2021, 1, 2)

    with pytest.raises(TypeError) as e:
        valid_timestream_extractor_object.fetch_data(
            plant_id=invalid_plant_id,
            start_datetime=start_datetime,
            end_datetime=end_datetime,
        )
    assert str(e.value) == "plant_id must be an integer."


def test_fetch_data_with_invalid_start_datetime_type_raises_error(
    valid_timestream_extractor_object,
):
    valid_plant_id = 123
    invalid_start_datetime = "2021-01-01"
    end_datetime = datetime(2021, 1, 2)

    with pytest.raises(TypeError) as e:
        valid_timestream_extractor_object.fetch_data(
            plant_id=valid_plant_id,
            start_datetime=invalid_start_datetime,
            end_datetime=end_datetime,
        )
    assert str(e.value) == "start_datetime must be a datetime object."


def test_fetch_data_with_invalid_end_datetime_type_raises_error(
    valid_timestream_extractor_object,
):
    valid_plant_id = 123
    start_datetime = datetime(2021, 1, 1)
    invalid_end_datetime = "2021-01-02"

    with pytest.raises(TypeError) as e:
        valid_timestream_extractor_object.fetch_data(
            plant_id=valid_plant_id,
            start_datetime=start_datetime,
            end_datetime=invalid_end_datetime,
        )
    assert str(e.value) == "end_datetime must be a datetime object."


def test_initialisation_timestream_data_extraction_raises_with_empty_company_name():
    valid_plant_id = 123
    valid_start_date = pd.to_datetime("2021-01-01")
    valid_end_date = pd.to_datetime("2021-01-02")
    valid_metadata_api_object = MagicMock()
    valid_metadata_api_object.get_company_name.return_value = None
    valid_aws_session = MagicMock()
    valid_aws_timestream_client = MagicMock()
    with pytest.raises(ValueError) as e:
        extractor = TimestreamDataExtractor(
            aws_timestream_client=valid_aws_timestream_client,
            metadata_api_object=valid_metadata_api_object,
            boto3_session=valid_aws_session,
        )
        extractor.fetch_data(
            plant_id=valid_plant_id,
            start_datetime=valid_start_date,
            end_datetime=valid_end_date,
        )
    assert str(e.value) == f"Company name not found for plant ID: {valid_plant_id}"


def test_fetch_data_passes_with_valid_arguments_no_chunking_invalid_dataframe():
    valid_plant_id = 123
    valid_metadata_api_object = MagicMock()
    valid_metadata_api_object.get_company_name.return_value = "TestCompany"
    start_date = pd.to_datetime("2021-01-01")
    end_date = pd.to_datetime("2021-01-02")
    aws_session = MagicMock()
    aws_timestream_client = MagicMock()
    aws_timestream_client.query.return_value = pd.Series([1, 2, 3])
    extractor = TimestreamDataExtractor(
        aws_timestream_client=aws_timestream_client,
        metadata_api_object=valid_metadata_api_object,
        boto3_session=aws_session,
    )
    with pytest.raises(Exception):
        timestream_data = extractor.fetch_data(
            plant_id=valid_plant_id, start_datetime=start_date, end_datetime=end_date
        )
        assert timestream_data == pd.DataFrame()


def test_fetch_data_passes_with_valid_arguments_with_chunking():
    test_file_path = os.path.join(os.path.dirname(__file__), "test_data_timestream.csv")
    test_data_frame = pd.read_csv(test_file_path)
    test_data_frame.index = test_data_frame["time"]
    test_data_frame.drop(columns=["measure_name", "time"], inplace=True)
    valid_plant_id = 123
    valid_metadata_api_object = MagicMock()
    valid_metadata_api_object.get_company_name.return_value = "TestCompany"
    start_date = pd.to_datetime("2021-01-01")
    end_date = pd.to_datetime("2021-01-02")
    aws_session = MagicMock()
    aws_timestream_client = MagicMock()
    aws_timestream_client.query.return_value = dataframe_generator_from_test_file()
    extractor = TimestreamDataExtractor(
        aws_timestream_client=aws_timestream_client,
        metadata_api_object=valid_metadata_api_object,
        boto3_session=aws_session,
    )
    timestream_data = extractor.fetch_data(
        plant_id=valid_plant_id,
        start_datetime=start_date,
        end_datetime=end_date,
        do_chunking=True,
    )
    assert timestream_data.equals(test_data_frame)


def test_fetch_data_passes_with_custom_sql_query(valid_timestream_extractor_object):
    custom_sql_query = "SELECT * FROM my_table WHERE time between '2024-05-01 00:00:00' and '2024-05-01 00:45:00'"
    mock_df = pd.DataFrame(
        {
            "data": [1, 2, 3, 4],
            "datetime": pd.date_range(
                start=pd.to_datetime("2024-05-01 00:00:00"),
                end=pd.to_datetime("2024-05-01 00:45:00"),
                freq="15T",
            ),
        }
    )  # Mocked
    mock_df.set_index("datetime", inplace=True)
    with patch.object(
        valid_timestream_extractor_object, "_query_timestream_db", return_value=mock_df
    ) as mock_query_db:
        result = valid_timestream_extractor_object.fetch_data(
            custom_sql_query=custom_sql_query
        )

    mock_query_db.assert_called_once_with(custom_sql_query, do_chunking=False)
    assert result.equals(mock_df)
