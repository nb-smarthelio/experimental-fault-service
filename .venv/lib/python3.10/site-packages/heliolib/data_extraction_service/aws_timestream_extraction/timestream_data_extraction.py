"""
A module for extracting data from AWS TimestreamDB.
"""

import inspect
import logging
import os
from datetime import datetime
from typing import Iterator, Optional

import boto3
import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)


class TimestreamDataExtractor:
    """
    A class for extracting data from AWS TimestreamDB.

    This class provides methods to fetch data from a Timestream database using aws timestream client for a specific date range,
    and for specific identifiers like inverter IDs (inv_ids) and MPPT IDs (mppt_ids).

    Parameters:
    ----------
    aws_timestream_client : AWS Wrangler Timestream client
        The AWS Wrangler Timestream client to use for Timestream DB queries, e.g. awswrangler.timestream.
    metadata_api_object : MetadataAPI
        The MetadataAPI object to use for fetching company names.
    boto3_session : boto3.Session, optional
        The AWS boto session to use for Timestream DB queries.
        If not provided, a session will be initialized using the AWS_REGION environment variable.
        If AWS_REGION is not set in the environment, an error will be raised.

    Methods:
    -------
    fetch_data(plant_id, start_datetime, end_datetime, custom_sql_query) : pandas.DataFrame
        Fetches data from Timestream for the specified date range or using a custom SQL query.

    Examples:
    --------
    import awswrangler as wr

    aws_timestream_client = wr.timestream
    plant_id = 123
    metadata_api_object = MetadataAPI()
    boto3_session = boto3.Session(region_name="eu-west-1")
    start_datetime = datetime(2021, 1, 1)
    end_datetime = datetime(2021, 1, 2)
    extractor = TimestreamDataExtractor(aws_timestream_client, metadata_api_object, boto3_session)
    data = extractor.fetch_data(plant_id, start_datetime, end_datetime)

    custom_sql_query = "SELECT * FROM ... WHERE ..."
    data = extractor.fetch_data(custom_sql_query=custom_sql_query)
    """

    def __init__(
        self,
        aws_timestream_client,
        metadata_api_object,
        boto3_session=None,
    ):
        """Initialize the TimestreamDataExtractor with necessary identifiers and an optional AWS session.

        Parameters:
        ----------
        aws_timestream_client : AWS Wrangler Timestream client
            The AWS Wrangler Timestream client to use for Timestream DB queries, e.g. awswrangler.timestream.
        metadata_api_object : MetadataAPI
            The MetadataAPI object to use for fetching company names.
            metadata_api_object.get_company_name(plant_id) should return the company name for the given plant ID.
        boto3_session : boto3.Session, optional
            The AWS boto session to use for Timestream DB queries.
            If not provided, a session will be initialized using the AWS_REGION environment variable.
            If AWS_REGION is not set in the environment, an error will be raised.

        Raises:
        ------
        ValueError
            If aws_timestream_client is None or lacks query method.
            If AWS_REGION environment variable is not set.
        """
        self.plant_id = None  # Placeholder for the plant ID, used to fetch company name to construct the query
        self.company_name = None
        if aws_timestream_client is None or aws_timestream_client.query is None:
            raise ValueError(
                "aws_timestream_client cannot be None or lacks query method."
            )
        self.aws_timestream_client = aws_timestream_client
        if metadata_api_object is None or not hasattr(
            metadata_api_object, "get_company_name"
        ):
            raise ValueError(
                "metadata_api_object cannot be None or lacks 'get_company_name' method."
            )
        self.metadata_api_object = metadata_api_object
        self.my_session = boto3_session or self._initialize_boto3_session()

    @staticmethod
    def _initialize_boto3_session():
        """
        Initializes an AWS boto3 session using the AWS_REGION environment variable.

        Returns:
        ----------
        boto3.Session: The initialized AWS session.

        Raises:
        ------
        ValueError
            If the AWS_REGION environment variable is not set.
        """
        aws_region = os.environ.get("AWS_REGION")
        if aws_region is None:
            error_message = "AWS_REGION not set in the environment variables"
            logger.error(error_message)
            raise ValueError(error_message)

        try:
            return boto3.Session(region_name=aws_region)
        except Exception as e:
            logger.exception(f"Error initializing AWS session: {e}")
            raise

    def _prepare_query(self, start_datetime, end_datetime):
        """
        Prepare and construct a SQL query based on the given start and end datetime.

        Parameters:
        ----------
        start_datetime : datetime.datetime, optional
            The start datetime of the time range.
        end_datetime : datetime.datetime, optional
            The end datetime of the time range.

        Returns:
        ----------
        str: The constructed SQL query.
        """
        # Begin constructing the query, starting with the SELECT statement
        query_parts = [f'SELECT * FROM "{self.company_name}".Plant_{self.plant_id}']

        # Initialize the list of query filters with the time range condition
        query_filters = [f"time between '{start_datetime}' and '{end_datetime}'"]

        # Combine the filters into a WHERE clause, avoiding an initial AND
        where_clause = " AND ".join(query_filters)
        if where_clause:
            query_parts.append("WHERE " + where_clause)

        # Combine all parts of the query into one string
        query = " ".join(query_parts)
        logger.info(f"Query prepared: {query}")
        return query

    @staticmethod
    def _preprocess_data(data: Optional[pd.DataFrame]) -> pd.DataFrame:
        if data is None or data.empty:
            logger.warning("No data found in query result. Returning empty DataFrame.")
            return pd.DataFrame()

        logger.info("Processing chunks of data.")
        if "measure_name" in data.columns:
            logger.debug("Dropping measure_name column from data.")
            data = data.drop(columns=["measure_name"])

        logger.debug("Setting time column as index.")
        data = data.set_index("time")

        logger.debug("Setting 'datetime' as index name.")
        data.index.name = "datetime"
        data = data.replace(-999, np.nan)

        return data

    def _combine_processed_chunks_of_data(
        self, query_iterator: Iterator
    ) -> pd.DataFrame:
        """Process and combine all chunks from the query iterator.

        Parameters:
        ----------
        query_iterator : Iterator
            An iterator that yields chunks of data as DataFrames.

        Returns:
        -------
        pandas.DataFrame
            A single DataFrame combining all processed chunks.
        """
        processed_chunks = []
        for data in query_iterator:
            logger.debug(
                f"Processing chunk of data by iterating over chunks generated by query_iterator: {data}"
            )
            processed_chunk = self._preprocess_data(data)
            if not processed_chunk.empty:
                processed_chunks.append(processed_chunk)
            else:
                logger.warning(
                    "No data found in query result. Skipping this chunk of data."
                )
        return (
            pd.concat(processed_chunks, axis=0) if processed_chunks else pd.DataFrame()
        )

    def _query_timestream_db(self, query: str, do_chunking: bool) -> pd.DataFrame:
        """Execute a query on Timestream DB and return the results.

        Parameters:
        ----------
        query : str
            The SQL query to execute.
        do_chunking: bool
            Bool which determines whether to chunk data or not during extraction

        Returns:
        -------
        pandas.DataFrame
            The result of the query as a Pandas DataFrame.
        """

        try:
            if do_chunking:
                query_iterator = self.aws_timestream_client.query(
                    query, boto3_session=self.my_session, chunked=True
                )

                # check if query_iterator is of type generator
                if not inspect.isgenerator(query_iterator):
                    raise TypeError(
                        "Error : query_iterator returned must be of type generator"
                    )
                timestream_data = self._combine_processed_chunks_of_data(query_iterator)
                logger.warning("Replaced all -999 values with nan")
            else:
                timestream_data = self.aws_timestream_client.query(
                    sql=query, boto3_session=self.my_session
                )
                if not isinstance(timestream_data, pd.DataFrame):
                    raise TypeError("Error: Expected a DataFrame from the query")

                timestream_data = self._preprocess_data(timestream_data)
                logger.warning("Replaced all -999 values with nan")

            return timestream_data
        except Exception as e:
            logger.exception(f"{e}: Error executing query on Timestream DB.")
            return pd.DataFrame()

    @staticmethod
    def _validate_date_range(start_datetime: datetime, end_datetime: datetime) -> None:
        """Validates the date range parameters.

        Parameters:
        ----------
        start_datetime : datetime.datetime
            The start datetime for the data extraction period.
        end_datetime : datetime.datetime
            The end datetime for the data extraction period.

        Raises:
        ------
        ValueError
            If the date range parameters are not provided.
        TypeError
            If `start_datetime` or `end_datetime` is not an instance of `datetime.datetime`.
        """
        if not start_datetime or not end_datetime:
            raise ValueError("Must provide either a date range or a custom SQL query.")
        if not isinstance(start_datetime, datetime):
            raise TypeError("start_datetime must be a datetime object.")
        if not isinstance(end_datetime, datetime):
            raise TypeError("end_datetime must be a datetime object.")

    def _fetch_data_for_date_range(
        self, start_datetime: datetime, end_datetime: datetime, do_chunking: bool
    ) -> pd.DataFrame:
        """
        Fetches data for a specific datetime range from Timestream.

        Parameters:
        ----------
        start_datetime : datetime.datetime
            The start datetime of the time range.
        end_datetime : datetime.datetime
            The end datetime of the time range.
        do_chunking : bool
        Bool which chunks data if true

        Returns:
        ----------
        pandas.DataFrame: DataFrame containing the fetched data.
        """
        # Prepare the query using the provided datetime range
        query = self._prepare_query(start_datetime, end_datetime)

        # Execute the query and return the results
        try:
            return self._query_timestream_db(query, do_chunking=do_chunking)
        except Exception as e:
            logger.exception(
                f"Failed to fetch data from Timestream for the range {start_datetime} to {end_datetime}: {e}"
            )
            return pd.DataFrame()  # Return an empty DataFrame on failure

    def _fetch_data_using_custom_query(
        self, custom_sql_query: str, do_chunking: bool
    ) -> pd.DataFrame:
        """Fetches data using a custom SQL query.

        Parameters:
        ----------
        custom_sql_query : str
            A custom SQL query to use for data extraction.
        do_chunking: bool
            Bool which chunks data if true

        Returns:
        -------
        pandas.DataFrame
            DataFrame containing the fetched data.

        Raises:
        ------
        ValueError
            If a custom SQL query is provided along with date range parameters.
        """
        logger.info(f"Fetching data using custom SQL query: {custom_sql_query}")
        try:
            return self._query_timestream_db(custom_sql_query, do_chunking=do_chunking)
        except Exception as e:
            logger.exception(
                f"Failed to fetch data from Timestream for the query: {custom_sql_query}, Error: {e}"
            )
            return pd.DataFrame()  # Return an empty DataFrame on failure

    def fetch_data(
        self,
        plant_id: int = None,
        start_datetime: datetime = None,
        end_datetime: datetime = None,
        custom_sql_query: str = None,
        do_chunking: bool = False,
    ):
        """Fetches data from Timestream for the specified date range or using a custom SQL query.

        Parameters:
        ----------
        plant_id : int, optional
            The plant ID for which to fetch data.
        start_datetime : datetime.datetime, optional
            The start datetime for the data extraction period.
        end_datetime : datetime.datetime, optional
            The end datetime for the data extraction period.
        custom_sql_query : str, optional
            A custom SQL query to use for data extraction.
        do_chunking : bool, optional
            bool which determines whether to chunk data during data extraction
            Chunks data if true

        Returns:
        -------
        pandas.DataFrame
            DataFrame containing the fetched data.

        Raises:
        ------
        ValueError
            If both start_datetime/end_datetime and custom_sql_query are provided or if neither is provided.
        TypeError
            If `start_datetime` or `end_datetime` is not an instance of `datetime.datetime` when provided.
            If `plant_id` is not an integer.

        Examples:
        --------
        from datetime import datetime
        plant_id = 123
        start_datetime = datetime(2021, 1, 1, 0, 0, 0)
        end_datetime = datetime(2021, 1, 2, 23, 59, 59)
        data = extractor.fetch_data(plant_id, start_datetime, end_datetime)

        custom_sql_query = "SELECT * FROM ... WHERE ..."
        data = extractor.fetch_data(custom_sql_query=custom_sql_query)
        """
        # Validate inputs
        if not custom_sql_query and not (start_datetime and end_datetime and plant_id):
            raise ValueError(
                "Must provide either a date range with plant id or a custom SQL query."
            )

        if custom_sql_query and (start_datetime or end_datetime or plant_id):
            raise ValueError(
                "Must provide either a plant id with date range or a custom SQL query, not both."
            )

        if custom_sql_query:
            return self._fetch_data_using_custom_query(custom_sql_query, do_chunking)

        if not isinstance(plant_id, int):
            raise TypeError("plant_id must be an integer.")
        self.plant_id = plant_id
        self.company_name = self.metadata_api_object.get_company_name(plant_id)
        if not self.company_name:
            raise ValueError(f"Company name not found for plant ID: {plant_id}")
        self._validate_date_range(start_datetime, end_datetime)
        return self._fetch_data_for_date_range(
            start_datetime, end_datetime, do_chunking
        )
